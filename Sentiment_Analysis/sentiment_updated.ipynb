{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed470a1",
   "metadata": {},
   "source": [
    "Reference: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccd94037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f77a402",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f16ef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a1bd247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61255765, 0.32987192, 0.05757042], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example prediction task\n",
    "\n",
    "text = \"It's meh\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "612b0fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) negative 0.6126\n",
      "2) neutral 0.3299\n",
      "3) positive 0.0576\n"
     ]
    }
   ],
   "source": [
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab0ab75",
   "metadata": {},
   "source": [
    "### Input Data Setup\n",
    "Load whichever input data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79429bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Predicting sentiment for the full dataset\\nmain_comment_df = pd.read_csv('data_2018_2023/comments.csv')\\nmain_comment_df.body = main_comment_df.body.fillna('')\\n\\n# Split into 40 batches as checkpoints\\nbatches = np.array_split(main_comment_df, 40)\\n\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Predicting sentiment for the full dataset\n",
    "main_comment_df = pd.read_csv('data_2018_2023/comments.csv')\n",
    "main_comment_df.body = main_comment_df.body.fillna('')\n",
    "\n",
    "# Split into 40 batches as checkpoints\n",
    "batches = np.array_split(main_comment_df, 40)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "01a98d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting sentiment for round 2 manual labels\n",
    "charlie_label_df = pd.read_csv('manual/charlie_comments.csv')\n",
    "dillan_label_df = pd.read_csv('manual/dillan_comments.csv')\n",
    "daniel_label_df = pd.read_csv('manual/daniel_comments.csv')\n",
    "\n",
    "comparison = pd.DataFrame()\n",
    "comparison['charlie_label'] = charlie_label_df.sentiment_label\n",
    "comparison['dillan_label'] = dillan_label_df.sentiment_label\n",
    "comparison['daniel_label'] = daniel_label_df.sentiment_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b7b29c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charlie_label</th>\n",
       "      <th>dillan_label</th>\n",
       "      <th>daniel_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   charlie_label  dillan_label daniel_label\n",
       "0              1             1            1\n",
       "1             -1            -1           -1\n",
       "2              1            -1            1\n",
       "3              1             1           -1\n",
       "4              1             1            0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecae6f5",
   "metadata": {},
   "source": [
    "### Prediction Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f475ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(batch_idx, text_idx, text, tokenizer, model):\n",
    "    try:\n",
    "        encoded_input = tokenizer(text, return_tensors='pt')\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        ranking = np.argsort(scores)\n",
    "        ranking = ranking[::-1]\n",
    "        pred_idx = np.argmax(scores)\n",
    "    except RuntimeError:\n",
    "        print('ERROR at batch %i text %i! Checking text length: %i' % (batch_idx, text_idx, len(text.split())))\n",
    "        return ('error', 0)\n",
    "    \n",
    "    return (config.id2label[pred_idx], scores[pred_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc921e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch_prediction(batch_idx, output_filename, batch, tokenizer, model):\n",
    "    text_list = list(batch.body)\n",
    "    prediction_list = [make_prediction(batch_idx, text_idx, text, tokenizer, model) for text_idx, text in enumerate(text_list)]\n",
    "    \n",
    "    batch['predicted_label'] = [pair[0] for pair in prediction_list]\n",
    "    batch['confidence'] = [pair[1] for pair in prediction_list]\n",
    "    batch.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(batch.predicted_label.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cd8341",
   "metadata": {},
   "source": [
    "#### 1. Manual label validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "68296300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR at batch 0 text 310! Checking text length: 549\n"
     ]
    }
   ],
   "source": [
    "validation_texts = charlie_label_df.body.fillna('')\n",
    "comparison['body'] = validation_texts\n",
    "\n",
    "output = [make_prediction(0, idx, text, tokenizer, model) for idx, text in enumerate(validation_texts)]\n",
    "comparison['model_label'] = [pair[0] for pair in output]\n",
    "comparison['model_label'] = comparison['model_label'].replace({'positive': 1, 'negative': -1, 'neutral': 0, 'error': 0})\n",
    "comparison['model_confidence'] = [pair[1] for pair in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eebe6061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charlie_label</th>\n",
       "      <th>dillan_label</th>\n",
       "      <th>daniel_label</th>\n",
       "      <th>body</th>\n",
       "      <th>model_label</th>\n",
       "      <th>model_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>congrats on passing!!!!!!! this is something t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>bro…relax</td>\n",
       "      <td>0</td>\n",
       "      <td>0.690845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>I had the same problem coming in as a freshman...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.376017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Well, can’t give ya comfort because I think th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.558477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Grades don’t really matter. I graduated years ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>It wasn’t a hard assignment, I started at 10:3...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.629152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Don’t be scared!!! If you can get through 280 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Just bomb that part of hw and it's just less t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.693472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>it takes 15 minutes to read the instructions, ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.559133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>no i dont think you do</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     charlie_label  dillan_label daniel_label  \\\n",
       "0                1             1            1   \n",
       "1               -1            -1           -1   \n",
       "2                1            -1            1   \n",
       "3                1             1           -1   \n",
       "4                1             1            0   \n",
       "..             ...           ...          ...   \n",
       "428              0             1            0   \n",
       "429              1             1            1   \n",
       "430             -1             0            0   \n",
       "431              0            -1            0   \n",
       "432              0            -1           -1   \n",
       "\n",
       "                                                  body  model_label  \\\n",
       "0    congrats on passing!!!!!!! this is something t...            1   \n",
       "1                                            bro…relax            0   \n",
       "2    I had the same problem coming in as a freshman...            1   \n",
       "3    Well, can’t give ya comfort because I think th...            0   \n",
       "4    Grades don’t really matter. I graduated years ...            0   \n",
       "..                                                 ...          ...   \n",
       "428  It wasn’t a hard assignment, I started at 10:3...            1   \n",
       "429  Don’t be scared!!! If you can get through 280 ...            1   \n",
       "430  Just bomb that part of hw and it's just less t...           -1   \n",
       "431  it takes 15 minutes to read the instructions, ...           -1   \n",
       "432                             no i dont think you do            0   \n",
       "\n",
       "     model_confidence  \n",
       "0            0.974098  \n",
       "1            0.690845  \n",
       "2            0.376017  \n",
       "3            0.558477  \n",
       "4            0.478843  \n",
       "..                ...  \n",
       "428          0.629152  \n",
       "429          0.910908  \n",
       "430          0.693472  \n",
       "431          0.559133  \n",
       "432          0.514990  \n",
       "\n",
       "[433 rows x 6 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "138d1920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1      0\n",
       "2      2\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "428    1\n",
       "429    3\n",
       "430    1\n",
       "431    1\n",
       "432    1\n",
       "Length: 433, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the number of annotators that the model agrees with for each text\n",
    "level_of_match = (comparison.charlie_label == comparison.model_label).astype(int) + (comparison.dillan_label == comparison.model_label).astype(int) + (comparison.daniel_label == comparison.model_label.astype(str)).astype(int)\n",
    "level_of_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2fdb33f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    221\n",
       "2     95\n",
       "1     71\n",
       "0     46\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_of_match.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5b3df",
   "metadata": {},
   "source": [
    "======================================================================================================\n",
    "#### 2. Full dataset prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea9e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for idx, batch in enumerate(batches):\n",
    "    output_filename = 'full_data_batch_label/labeled/batch_%i.csv' % idx\n",
    "    make_batch_prediction(idx, output_filename, batch, tokenizer, model)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59b960f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
