{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed470a1",
   "metadata": {},
   "source": [
    "Reference: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ccd94037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9842f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_COMMENT_PATH = 'data_2018_2023/comments.csv'\n",
    "RAW_POST_PATH = 'data_2018_2023/posts.csv'\n",
    "\n",
    "CHARLIE_LABEL_PATH = 'manual/charlie_comments.csv'\n",
    "DANIEL_LABEL_PATH = 'manual/daniel_comments.csv'\n",
    "DILLAN_LABEL_PATH = 'manual/dillan_comments.csv'\n",
    "\n",
    "COMMENT_OUTPUT_DIR = 'full_data_batch_label/labeled_comments'\n",
    "POST_OUTPUT_DIR = 'full_data_batch_label/labeled_posts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ffee184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(batch_idx, text_idx, text, tokenizer, model):\n",
    "    '''Acquire sentiment prediction for a single text.'''\n",
    "    try:\n",
    "        encoded_input = tokenizer(text, return_tensors='pt')\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        ranking = np.argsort(scores)\n",
    "        ranking = ranking[::-1]\n",
    "        pred_idx = np.argmax(scores)\n",
    "    except:\n",
    "        print('Failed to predict sentiment for batch %i text %i!' % (batch_idx, text_idx))\n",
    "        return ('error', 0)\n",
    "    \n",
    "    return (config.id2label[pred_idx], scores[pred_idx])\n",
    "\n",
    "\n",
    "def make_batch_prediction(batch_idx, output_filename, batch, tokenizer, model):\n",
    "    '''Acquire sentiment prediction for a batch of texts'''\n",
    "    text_list = list(batch.body)\n",
    "    prediction_list = [make_prediction(batch_idx, text_idx, text, tokenizer, model) for text_idx, text in enumerate(text_list)]\n",
    "    \n",
    "    batch['predicted_label'] = [pair[0] for pair in prediction_list]\n",
    "    batch['confidence'] = [pair[1] for pair in prediction_list]\n",
    "    batch.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(batch.predicted_label.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f77a402",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f16ef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1bd247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61255765, 0.32987192, 0.05757042], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example prediction task\n",
    "\n",
    "text = \"It's meh\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612b0fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) negative 0.6126\n",
      "2) neutral 0.3299\n",
      "3) positive 0.0576\n"
     ]
    }
   ],
   "source": [
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab0ab75",
   "metadata": {},
   "source": [
    "### Input Data Setup\n",
    "Load data for the main prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79429bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting sentiment for the full dataset\n",
    "main_comment_df = pd.read_csv(RAW_COMMENT_PATH)\n",
    "main_post_df = pd.read_csv(RAW_POST_PATH)\n",
    "\n",
    "main_comment_df.body = main_comment_df.body.fillna('')\n",
    "main_post_df.title_text_combined = main_post_df.title_text_combined.fillna('')\n",
    "\n",
    "# Rename the text field in post df to be consistent with comment df\n",
    "main_post_df.rename({'title_text_combined': 'body'}, axis=1, inplace=True)\n",
    "\n",
    "# Split into 40 or 4 batches as checkpoints to recover from interruptions\n",
    "comment_batches = np.array_split(main_comment_df, 40)\n",
    "post_batches = np.array_split(main_post_df, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661bb5b8",
   "metadata": {},
   "source": [
    "Or load manually annotated subset for model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01a98d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charlie_label</th>\n",
       "      <th>dillan_label</th>\n",
       "      <th>daniel_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   charlie_label  dillan_label daniel_label\n",
       "0              1             1            1\n",
       "1             -1            -1           -1\n",
       "2              1            -1            1\n",
       "3              1             1           -1\n",
       "4              1             1            0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting sentiment for round 2 manual labels\n",
    "charlie_label_df = pd.read_csv(CHARLIE_LABEL_PATH)\n",
    "dillan_label_df = pd.read_csv(DILLAN_LABEL_PATH)\n",
    "daniel_label_df = pd.read_csv(DANIEL_LABEL_PATH)\n",
    "\n",
    "comparison = pd.DataFrame()\n",
    "comparison['charlie_label'] = charlie_label_df.sentiment_label\n",
    "comparison['dillan_label'] = dillan_label_df.sentiment_label\n",
    "comparison['daniel_label'] = daniel_label_df.sentiment_label\n",
    "comparison.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecae6f5",
   "metadata": {},
   "source": [
    "### Prediction Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc9104",
   "metadata": {},
   "source": [
    "#### 1. Manual label validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d00a4dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to predict sentiment for batch 0 text 310!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charlie_label</th>\n",
       "      <th>dillan_label</th>\n",
       "      <th>daniel_label</th>\n",
       "      <th>body</th>\n",
       "      <th>model_label</th>\n",
       "      <th>model_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>congrats on passing!!!!!!! this is something t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>bro…relax</td>\n",
       "      <td>0</td>\n",
       "      <td>0.690845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>I had the same problem coming in as a freshman...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.376017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Well, can’t give ya comfort because I think th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.558477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Grades don’t really matter. I graduated years ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   charlie_label  dillan_label daniel_label  \\\n",
       "0              1             1            1   \n",
       "1             -1            -1           -1   \n",
       "2              1            -1            1   \n",
       "3              1             1           -1   \n",
       "4              1             1            0   \n",
       "\n",
       "                                                body  model_label  \\\n",
       "0  congrats on passing!!!!!!! this is something t...            1   \n",
       "1                                          bro…relax            0   \n",
       "2  I had the same problem coming in as a freshman...            1   \n",
       "3  Well, can’t give ya comfort because I think th...            0   \n",
       "4  Grades don’t really matter. I graduated years ...            0   \n",
       "\n",
       "   model_confidence  \n",
       "0          0.974098  \n",
       "1          0.690845  \n",
       "2          0.376017  \n",
       "3          0.558477  \n",
       "4          0.478843  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_texts = charlie_label_df.body.fillna('')\n",
    "comparison['body'] = validation_texts\n",
    "\n",
    "output = [make_prediction(0, idx, text, tokenizer, model) for idx, text in enumerate(validation_texts)]\n",
    "comparison['model_label'] = [pair[0] for pair in output]\n",
    "comparison['model_label'] = comparison['model_label'].replace({'positive': 1, 'negative': -1, 'neutral': 0, 'error': 0})\n",
    "comparison['model_confidence'] = [pair[1] for pair in output]\n",
    "comparison.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff00cd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_of_match</th>\n",
       "      <th>number_of_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_of_match  number_of_match\n",
       "0               3              221\n",
       "1               2               95\n",
       "2               1               71\n",
       "3               0               46"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the number of annotators that the model agrees with for each text\n",
    "accuracy = (comparison.charlie_label == comparison.model_label).astype(int) + (comparison.dillan_label == comparison.model_label).astype(int) + (comparison.daniel_label == comparison.model_label.astype(str)).astype(int)\n",
    "accuracy = pd.DataFrame(accuracy.value_counts()).reset_index()\n",
    "accuracy.columns = ['level_of_match', 'number_of_match']\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c1116a",
   "metadata": {},
   "source": [
    "<b>Validation Results\n",
    "* Total number of observations: 433\n",
    "* Percentage of model predictions that matches at least two human labels: 0.73\n",
    "* Percentage of model predictions that matches at least one human label: 0.89"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0c0c4",
   "metadata": {},
   "source": [
    "======================================================================================================\n",
    "#### 2. Full dataset prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b844a2",
   "metadata": {},
   "source": [
    "<b>Comments Sentiment Predictions\n",
    "* Rough estimation of sentiment distribution: Neutral-50%, Positive-25%, Negative-25%, Error-0.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea9e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(comment_batches):\n",
    "    output_filename = os.path.join(COMMENT_OUTPUT_DIR, 'batch_%i.csv' % idx)\n",
    "    make_batch_prediction(idx, output_filename, batch, tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efdb7ed",
   "metadata": {},
   "source": [
    "<b>Posts Sentiment Predictions\n",
    "* Rough estimation of sentiment distribution: Neutral-73%, Positive-9%, Negative-18%, Error-0.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(post_batches):\n",
    "    output_filename = os.path.join(POST_OUTPUT_DIR, 'batch_%i.csv' % idx)\n",
    "    make_batch_prediction(idx, output_filename, batch, tokenizer, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
